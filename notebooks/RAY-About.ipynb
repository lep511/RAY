{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabb527-9839-483a-92bb-d3c32dcb7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Suppress noisy requests warnings.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4cde31-0978-48a9-bf81-6fcc65409aab",
   "metadata": {},
   "source": [
    "* Ray es un proyecto de código abierto para Python paralelo y distribuido.\n",
    "\n",
    "* La computación paralela y distribuida es un elemento básico de las aplicaciones modernas. Necesitamos aprovechar varios núcleos o varias máquinas para acelerar las aplicaciones o ejecutarlas a gran escala. La infraestructura para rastrear la web y responder a las consultas de búsqueda no son programas de un solo hilo que se ejecutan en el portátil de alguien, sino conjuntos de servicios que se comunican e interactúan entre sí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df3f18-87fc-43cd-8260-0906c5159606",
   "metadata": {},
   "source": [
    "### ¿Por qué Ray?\n",
    "\n",
    "Muchos tutoriales explican cómo utilizar el módulo de multiprocesamiento de Python. Desafortunadamente, el módulo de multiprocesamiento está severamente limitado en su capacidad para manejar los requerimientos de las aplicaciones modernas. Estos requisitos incluyen los siguientes:\n",
    "\n",
    "* Ejecutar el mismo código en más de una máquina.\n",
    "* Construir microservicios y actores que tengan estado y puedan comunicarse.\n",
    "* Manejar con gracia los fallos de la máquina.\n",
    "* Manejo eficiente de objetos grandes y datos numéricos.\n",
    "\n",
    "Ray aborda todos estos puntos, simplifica las cosas sencillas y hace posible un comportamiento complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3200a-b77b-4d83-b169-3d1ea5826051",
   "metadata": {},
   "source": [
    "### Conceptos necesarios\n",
    "La programación tradicional se basa en dos conceptos fundamentales: funciones y clases. Utilizando estos bloques de construcción, los lenguajes de programación nos permiten construir innumerables aplicaciones.\n",
    "\n",
    "Sin embargo, cuando migramos nuestras aplicaciones al entorno distribuido, los conceptos suelen cambiar.\n",
    "\n",
    "En un extremo del espectro, tenemos herramientas como OpenMPI, el multiprocesamiento de Python y ZeroMQ, que proporcionan primitivas de bajo nivel para enviar y recibir mensajes. Estas herramientas son muy potentes, pero proporcionan una abstracción diferente, por lo que las aplicaciones de un solo hilo deben reescribirse desde cero para utilizarlas.\n",
    "\n",
    "En el otro extremo del espectro, tenemos herramientas de dominio específico como TensorFlow para la formación de modelos, Spark para el procesamiento de datos y SQL, y Flink para el procesamiento de flujos. Estas herramientas proporcionan abstracciones de alto nivel como redes neuronales, conjuntos de datos y flujos. Sin embargo, como difieren de las abstracciones utilizadas para la programación en serie, las aplicaciones deben reescribirse desde cero para aprovecharlas.\n",
    "\n",
    "<br>\n",
    "\n",
    "![Image](https://miro.medium.com/max/720/1*CFtsBP134JiGeQQqoKNcXw.webp)\n",
    "\n",
    "Ray ocupa un lugar intermedio único. En lugar de introducir nuevos conceptos. Ray toma los conceptos existentes de funciones y clases y los traslada al entorno distribuido como tareas y actores. Esta elección de API permite paralelizar aplicaciones en serie sin grandes modificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ef707-2dff-467a-b21c-3ad074c885fa",
   "metadata": {},
   "source": [
    "### Iniciar Ray\n",
    "\n",
    "El comando `ray.init()` inicia todos los procesos Ray relevantes. En un cluster, esta es la única línea que necesita cambiar (necesitamos pasar la dirección del cluster). Estos procesos incluyen lo siguiente:\n",
    "\n",
    "* Un número de procesos trabajadores para ejecutar funciones Python en paralelo (aproximadamente un trabajador por núcleo de CPU).\n",
    "* Un proceso planificador para asignar \"tareas\" a los trabajadores (y a otras máquinas). Una tarea es la unidad de trabajo programada por Ray y corresponde a una invocación de función o método.\n",
    "* Un almacén de objetos en memoria compartida para compartir objetos eficientemente entre los trabajadores (sin crear copias).\n",
    "* Una base de datos en memoria para almacenar los metadatos necesarios para volver a ejecutar tareas en caso de fallo de la máquina.\n",
    "\n",
    "Los trabajadores Ray son procesos separados en lugar de hilos porque el soporte para multihilos en Python es muy limitado debido al bloqueo global del intérprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a083f14-1127-4599-a8bc-a13c3f7c2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d64bee-7cbe-4540-9d57-b752936b6358",
   "metadata": {},
   "source": [
    "### Paralelismo con tareas\n",
    "\n",
    "Para convertir una función f de Python en una \"función remota\" (una función que puede ejecutarse de forma remota y asíncrona), declaramos la función con el decorador `@ray.remote`. Entonces, las invocaciones a la función a través de f.remote() devolverán inmediatamente futuros (un futuro es una referencia a la eventual salida), y la ejecución real de la función tendrá lugar en segundo plano (nos referimos a esta ejecución como una tarea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e18df-05c6-4d19-b7a7-b764c2ced2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f(x):\n",
    "    time.sleep(1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f1f4c-676c-40bd-9ac7-24eedb2b39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start 4 tasks in parallel.\n",
    "result_ids = []\n",
    "for i in range(4):\n",
    "    result_ids.append(f.remote(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13c687-cb9d-4324-acc8-536337ff44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ray.get(result_ids)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb341d2-d443-458d-a157-c76f90e21a09",
   "metadata": {},
   "source": [
    "Dado que la llamada a `f.remote(i)` retorna inmediatamente, se pueden ejecutar cuatro copias de f en paralelo simplemente ejecutando esa línea cuatro veces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97609923-3487-417b-b99a-0fcf064f4a6e",
   "metadata": {},
   "source": [
    "### Dependencia de tareas\n",
    "\n",
    "Las tareas también pueden depender de otras tareas. A continuación, la tarea multiply_matrices utiliza las salidas de las dos tareas create_matrix, por lo que no comenzará a ejecutarse hasta que se hayan ejecutado las dos primeras tareas. Las salidas de las dos primeras tareas se pasarán automáticamente como argumentos a la tercera tarea y los futuros se sustituirán por sus valores correspondientes). De este modo, las tareas pueden componerse con dependencias DAG arbitrarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b34bc-c812-4742-8813-ccdb7d5858ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@ray.remote\n",
    "def create_matrix(size):\n",
    "    return np.random.normal(size=size)\n",
    "\n",
    "@ray.remote\n",
    "def multiply_matrices(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "x_id = create_matrix.remote([1000, 1000])\n",
    "y_id = create_matrix.remote([1000, 1000])\n",
    "z_id = multiply_matrices.remote(x_id, y_id)\n",
    "\n",
    "# Get the results.\n",
    "z = ray.get(z_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13addf5d-f5aa-43e3-bda3-0a58d3d4a82c",
   "metadata": {},
   "source": [
    "### Agregación eficaz de valores\n",
    "\n",
    "Las relaciones de tareas pueden utilizarse de formas mucho más sofisticadas. Por ejemplo, supongamos que queremos agregar 8 valores. Este ejemplo utiliza la suma de números enteros, pero en muchas aplicaciones, la agregación de grandes vectores a través de múltiples máquinas puede ser un cuello de botella. En este caso, el cambio de una sola línea de código puede cambiar el tiempo de ejecución de la agregación de lineal a logarítmico en el número de valores que se agregan.\n",
    "\n",
    "<br>\n",
    "\n",
    "![Image](https://miro.medium.com/max/720/1*vHz3troEmr4uLns0V8VmdA.webp)\n",
    "\n",
    "Como se ha descrito anteriormente, para alimentar la salida de una tarea como entrada en una tarea posterior, basta con pasar el futuro devuelto por la primera tarea como argumento en la segunda tarea. El programador de Ray tendrá en cuenta automáticamente esta dependencia entre tareas. La segunda tarea no se ejecutará hasta que la primera haya terminado, y la salida de la primera tarea se enviará automáticamente a la máquina en la que se esté ejecutando la segunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65249b-018c-4f38-85b2-06c4d6696364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@ray.remote\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y\n",
    "\n",
    "# Aggregate the values slowly. This approach takes O(n) where n is the\n",
    "# number of values being aggregated. In this case, 7 seconds.\n",
    "id1 = add.remote(1, 2)\n",
    "id2 = add.remote(id1, 3)\n",
    "id3 = add.remote(id2, 4)\n",
    "id4 = add.remote(id3, 5)\n",
    "id5 = add.remote(id4, 6)\n",
    "id6 = add.remote(id5, 7)\n",
    "id7 = add.remote(id6, 8)\n",
    "result = ray.get(id7)\n",
    "\n",
    "# Aggregate the values in a tree-structured pattern. This approach\n",
    "# takes O(log(n)). In this case, 3 seconds.\n",
    "id1 = add.remote(1, 2)\n",
    "id2 = add.remote(3, 4)\n",
    "id3 = add.remote(5, 6)\n",
    "id4 = add.remote(7, 8)\n",
    "id5 = add.remote(id1, id2)\n",
    "id6 = add.remote(id3, id4)\n",
    "id7 = add.remote(id5, id6)\n",
    "result = ray.get(id7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62489189-6407-4e88-a33e-e159cda196d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a6a11-af6b-4066-b23e-935e35a00c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow approach.\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "while len(values) > 1:\n",
    "    values = [add.remote(values[0], values[1])] + values[2:]\n",
    "result = ray.get(values[0])\n",
    "\n",
    "\n",
    "# Fast approach.\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "while len(values) > 1:\n",
    "    values = values[2:] + [add.remote(values[0], values[1])]\n",
    "result = ray.get(values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b675d8-e8a2-46ab-aeb5-e6b01ea79aa8",
   "metadata": {},
   "source": [
    "### De las clases a los actores\n",
    "Es un reto escribir aplicaciones interesantes sin usar clases, y esto es tan cierto en el entorno distribuido como en un único núcleo.\n",
    "\n",
    "Ray te permite tomar una clase Python y declararla con el decorador `@ray.remote`. Cada vez que se instancia la clase, Ray crea un nuevo \"actor\", que es un proceso que se ejecuta en algún lugar del clúster y contiene una copia del objeto. Las invocaciones a métodos en ese actor se convierten en tareas que se ejecutan en el proceso del actor y pueden acceder y mutar el estado del actor. De este modo, los actores permiten que el estado mutable se comparta entre múltiples tareas de un modo que las funciones remotas no permiten.\n",
    "\n",
    "Los actores individuales ejecutan métodos en serie (cada método individual es atómico) para que no haya condiciones de carrera. El paralelismo puede lograrse mediante la creación de múltiples actores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75627d-2435-4638-a686-ff39878c895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "    \n",
    "    def inc(self):\n",
    "        self.x += 1\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.x\n",
    "\n",
    "# Create an actor process.\n",
    "c = Counter.remote()\n",
    "\n",
    "# Check the actor's counter value.\n",
    "print(ray.get(c.get_value.remote()))  # 0\n",
    "\n",
    "# Increment the counter twice and check the value again.\n",
    "c.inc.remote()\n",
    "c.inc.remote()\n",
    "print(ray.get(c.get_value.remote()))  # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf25c3-ae93-4a1b-95da-9c3cfd21752c",
   "metadata": {},
   "source": [
    "El ejemplo anterior es el uso más simple posible de los actores. La línea `Counter.remote()` crea un nuevo proceso actor, que tiene una copia del objeto `Counter`. Las llamadas a `c.get_value.remote()` y `c.inc.remote()` ejecutan tareas en el proceso actor remoto y mutan el estado del actor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7cda18-8f15-4511-8f57-0a59bb412cd0",
   "metadata": {},
   "source": [
    "#### Manejadores de Actor\n",
    "\n",
    "En el ejemplo anterior, sólo invocamos métodos en el actor desde el script principal de Python. Uno de los aspectos más poderosos de los actores es que podemos pasar manejadores a un actor, lo que permite a otros actores u otras tareas invocar métodos en el mismo actor.\n",
    "\n",
    "El siguiente ejemplo crea un actor que almacena mensajes. Varias tareas de trabajo envían mensajes al actor repetidamente, y el script principal de Python lee los mensajes periódicamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02ced03-d427-4c44-8466-093325f4fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class MessageActor(object):\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "    \n",
    "    def add_message(self, message):\n",
    "        self.messages.append(message)\n",
    "    \n",
    "    def get_and_clear_messages(self):\n",
    "        messages = self.messages\n",
    "        self.messages = []\n",
    "        return messages\n",
    "\n",
    "\n",
    "# Define a remote function which loops around and pushes\n",
    "# messages to the actor.\n",
    "@ray.remote\n",
    "def worker(message_actor, j):\n",
    "    for i in range(100):\n",
    "        time.sleep(1)\n",
    "        message_actor.add_message.remote(\n",
    "            \"Message {} from worker {}.\".format(i, j))\n",
    "\n",
    "\n",
    "# Create a message actor.\n",
    "message_actor = MessageActor.remote()\n",
    "\n",
    "# Start 3 tasks that push messages to the actor.\n",
    "[worker.remote(message_actor, j) for j in range(3)]\n",
    "\n",
    "# Periodically get the messages and print them.\n",
    "for _ in range(10):\n",
    "    new_messages = ray.get(message_actor.get_and_clear_messages.remote())\n",
    "    print(\"New messages:\", new_messages)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5848c1-d426-4c04-bcb8-1ef1b998da1b",
   "metadata": {},
   "source": [
    "* Los actores son extremadamente potentes. Permiten tomar una clase Python e instanciarla como un microservicio que puede ser consultado desde otros actores y tareas e incluso desde otras aplicaciones.\n",
    "\n",
    "* Las tareas y los actores son las abstracciones básicas que proporciona Ray. Estos dos conceptos son muy generales y se pueden utilizar para implementar aplicaciones sofisticadas, incluidas las bibliotecas integradas de Ray para el aprendizaje por refuerzo, el ajuste de hiperparámetros, la aceleración de Pandas, y mucho más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc720b26-5e51-4c4d-af5c-7b5ece8d05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17718d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "# Download the file from S3.\n",
    "bucket = 'nyc-tlc'\n",
    "s3.Bucket(bucket).download_file('csv_backup/yellow_tripdata_2011-04.csv', '../data/yellow_tripdata_2011-04.csv')\n",
    "s3.Bucket(bucket).download_file('csv_backup/yellow_tripdata_2009-12.csv', '../data/yellow_tripdata_2009-12.csv')\n",
    "s3.Bucket(bucket).download_file('csv_backup/yellow_tripdata_2010-06.csv', '../data/yellow_tripdata_2010-06.csv')\n",
    "s3.Bucket(bucket).download_file('csv_backup/yellow_tripdata_2010-07.csv', '../data/yellow_tripdata_2010-07.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c877a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = '../data/'\n",
    "list_files = os.listdir(direct)\n",
    "list_filtered = []\n",
    "for file in list_files:\n",
    "    if file.startswith('yellow_tripdata'):\n",
    "        ds_csv = ray.data.read_csv(os.path.abspath('../data/' + file))\n",
    "        ds_csv.repartition(12).write_parquet(f'../data/parquet/{file[:-4]}')\n",
    "        del ds_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e05199",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ray.data.read_parquet('../data/parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ee7b4-a7f9-44f9-a7bb-f4bde4cb26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 blocks for parallelism\n",
    "ds = ds.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b33fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = ds.count()\n",
    "print('Total rows: {:,}'.format(total_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ad03a-c5e4-426b-ace3-cb2be9fd1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf5477-b3f6-48c9-b976-caa1a4054021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_batch(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[(df[\"Trip_Distance\"] > 2) & (df[\"Passenger_Count\"] > 2)]\n",
    "\n",
    "transformed_ds = ds.map_batches(transform_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62fa55-046a-4eb2-ac4a-a665c2b0bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ds.limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523d5f2-806b-4a83-a71e-a03c649d2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = transformed_ds.count()\n",
    "print('Total rows: {:,}'.format(total_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26f447-2ead-4b7f-aac4-11cd716914f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly stop\n",
    "ray.shutdown()\n",
    "assert not ray.is_initialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572299c-c8e2-4fd4-ada8-b9fa16ad2b3e",
   "metadata": {},
   "source": [
    "## Ejemplo: Ingesta de ML a gran escala\n",
    "\n",
    "En este ejemplo, aprenderá a crear, desplegar y escalar una canalización de ingestión aleatoria de aprendizaje automático utilizando Ray Dataset y Dataset Pipelines.\n",
    "\n",
    "* Cómo construir una tubería de ingesta aleatoria que carga, mezcla y alimenta datos en entrenadores distribuidos en unas pocas líneas de código;\n",
    "\n",
    "* Cómo escalar el pipeline desde la ingesta de datos de 100MiB a datos de 500GiB.\n",
    "\n",
    "![Image](https://docs.ray.io/en/master/_images/dataset-repeat-2.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfd237-5ea4-4338-b4f8-5000536907d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "from ray.data.dataset_pipeline import DatasetPipeline\n",
    "from ray.data.datasource.datasource import RandomIntRowDatasource\n",
    "import tempfile\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf3903-8b00-4c18-9e2d-8487e50c7bf2",
   "metadata": {},
   "source": [
    "### Construir una cadena de ingesta aleatoria\n",
    "\n",
    "Un proceso de ingesta típico de aprendizaje automático consta de los 4 pasos siguientes:\n",
    "\n",
    "* Cargar los datos de entrenamiento desde un almacenamiento externo;\n",
    "* Iterar sobre los datos durante varias épocas;\n",
    "* En cada epoch, aplicar global shuffle para decorrelacionar los datos;\n",
    "* En cada época, dividir los datos barajados en fragmentos, y alimentar los fragmentos a los entrenadores distribuidos;\n",
    "\n",
    "Veamos cómo implementamos este proceso utilizando el conjunto de datos Ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1876694-27e1-4752-a804-9d6dd059d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shuffle_pipeline(\n",
    "    training_data_dir: str, num_epochs: int, num_shards: int\n",
    ") -> List[DatasetPipeline]:\n",
    "\n",
    "    return (\n",
    "        ray.data.read_parquet(training_data_dir)\n",
    "        .repeat(num_epochs)\n",
    "        .random_shuffle_each_window()\n",
    "        .split(num_shards, equal=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a5aa9-b52d-4003-ac3e-47a73003002e",
   "metadata": {},
   "source": [
    "Ahora hemos definido una función create_shuffle_pipeline que crea un pipeline de ingestión. Lee training_data_dir, itera durante num_epochs veces, donde en cada epoch baraja y divide los datos de entrenamiento en num_shards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594f3cb-e2b9-459b-b38b-38c7dc308c28",
   "metadata": {},
   "source": [
    "### Alimentar el pipeline a los entrenadores\n",
    "\n",
    "Implementemos también un TrainingWorker que consuma los datos barajados de cada shard.\n",
    "\n",
    "Para simplificar, definiremos un Ray Actor que emule a los training workers. Específicamente,\n",
    "\n",
    "1. Toma un shard del shuffle pipeline para entrenar;\n",
    "2. itera sobre el fragmento para obtener un conjunto de datos de entrenamiento por época;\n",
    "3. Luego consume el conjunto de datos por lotes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d83d38-eb53-4489-a599-d64c54842d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class TrainingWorker:\n",
    "    def __init__(self, rank: int, shard: DatasetPipeline):\n",
    "        self.rank = rank\n",
    "        self.shard = shard\n",
    "\n",
    "    def train(self):\n",
    "        for epoch, training_dataset in enumerate(self.shard.iter_epochs()):\n",
    "            # Following code emulates epoch based SGD training.\n",
    "            print(f\"Training... worker: {self.rank}, epoch: {epoch}\")\n",
    "            for i, batch in enumerate(training_dataset.iter_batches()):\n",
    "                # TODO: replace the code for real training.\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea162a-e4f1-462d-9b0e-b1dd554fe460",
   "metadata": {},
   "source": [
    "Ejecutémoslo! Ahora vamos a ejecutar el canal de datos de extremo a extremo, primero, analicemos algunos argumentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf87f2b-e915-4616-8635-e2cf785d84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAINING_WORKERS = 4\n",
    "NUM_EPOCHS = 5\n",
    "NUM_COLUMNS = 10\n",
    "SIZE_100MiB = 100 * 1024 * 1024\n",
    "\n",
    "# create a local ray cluster.\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24b7c9-5fe9-41ab-9a42-9585d4619ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Count of nodes: {len(ray.nodes())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c30473-72c6-4275-aea6-8498470fc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = create_shuffle_pipeline(\n",
    "    filter_files, NUM_EPOCHS, NUM_TRAINING_WORKERS\n",
    ")\n",
    "\n",
    "training_workers = [\n",
    "    TrainingWorker.remote(rank, shard) for rank, shard in enumerate(splits)\n",
    "]\n",
    "\n",
    "# Let's run the e2e pipeline\n",
    "start = time.time()\n",
    "ray.get([worker.train.remote() for worker in training_workers])\n",
    "print(f\"total ingestion time: {int(time.time() - start)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66f69e-87d0-4c0f-8a51-a56ded2605b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the remote process\n",
    "@ray.remote\n",
    "class TrainingWorker:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be339ea4-408b-4199-83e6-0be969a40a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "@ray.remote\n",
    "class Task:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._thread = threading.Thread(target=self._run, daemon=True)\n",
    "        self._thread.start()\n",
    "    \n",
    "    def _run(self):\n",
    "        print('Started long-running task')\n",
    "        time.sleep(10)\n",
    "        print('You shouldn\\'t see this because the process has been killed')\n",
    "\n",
    "task = Task.remote()\n",
    "task.__ray_terminate__.remote()   # kills the process with an `exit(0)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

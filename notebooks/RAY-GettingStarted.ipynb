{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef91c4-9626-4f93-97ef-1550a899e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ray with support for the dashboard + cluster launcher\n",
    "# run: install_pkg.sh\n",
    "\n",
    "# Install Ray with minimal dependencies\n",
    "# !pip install -U ray\n",
    "\n",
    "# !pip install -U \"ray[air]\"     # installs Ray + dependencies for Ray AI Runtime\n",
    "# !pip install -U \"ray[tune]\"    # installs Ray + dependencies for Ray Tune\n",
    "# !pip install -U \"ray[rllib]\"   # installs Ray + dependencies for Ray RLlib\n",
    "# !pip install -U \"ray[serve]\"   # installs Ray + dependencies for Ray Serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c84c5ef-2896-4fdd-94ec-4659e799347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import warnings\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Suppress noisy requests warnings.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba95f736-2cfd-4cac-9ae2-217a7a3cb330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 14:12:38,871\tINFO worker.py:1352 -- Connecting to existing Ray cluster at address: 10.3.27.163:6379...\n",
      "2022-12-14 14:12:38,881\tINFO worker.py:1538 -- Connected to Ray cluster.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.10</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url=None, python_version='3.8.10', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '10.3.27.163', 'raylet_ip_address': '10.3.27.163', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-12-14_13-58-55_758402_417118/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-12-14_13-58-55_758402_417118/sockets/raylet', 'webui_url': None, 'session_dir': '/tmp/ray/session_2022-12-14_13-58-55_758402_417118', 'metrics_export_port': 51277, 'gcs_address': '10.3.27.163:6379', 'address': '10.3.27.163:6379', 'dashboard_agent_listen_port': 52365, 'node_id': '953abf3b1cf168d73f0fa3801949d1bb98e1c5170e18c784e2a35bb4'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3dd0619-0437-41f6-ab7e-f5128cb72cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(FileNotFoundError)",
     "evalue": "\u001b[36mray::_get_read_tasks()\u001b[39m (pid=424007, ip=10.3.27.163)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/read_api.py\", line 1586, in _get_read_tasks\n    reader = ds.create_reader(**kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/parquet_datasource.py\", line 165, in create_reader\n    return _ParquetDatasourceReader(**kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/parquet_datasource.py\", line 203, in __init__\n    _handle_read_os_error(e, paths)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/file_meta_provider.py\", line 367, in _handle_read_os_error\n    raise error\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/parquet_datasource.py\", line 199, in __init__\n    pq_ds = pq.ParquetDataset(\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/parquet/core.py\", line 1724, in __new__\n    return _ParquetDatasetV2(\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/parquet/core.py\", line 2423, in __init__\n    self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py\", line 755, in dataset\n    return _filesystem_dataset(source, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py\", line 442, in _filesystem_dataset\n    fs, paths_or_selector = _ensure_multiple_sources(source, filesystem)\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py\", line 361, in _ensure_multiple_sources\n    raise FileNotFoundError(info.path)\nFileNotFoundError: ../PySpark/taxi_data.parquet/part-00005-8a3a5378-d47c-4325-84e6-e9d4ff2c5b4d-c000.snappy.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(FileNotFoundError)\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fe1ceed8a0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Read Parquet files in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(paths, filesystem, columns, parallelism, ray_remote_args, tensor_column_schema, meta_provider, **arrow_parquet_args)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0marrow_parquet_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     )\n\u001b[0;32m--> 491\u001b[0;31m     return read_datasource(\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0mParquetDatasource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mparallelism\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_datasource\u001b[0;34m(datasource, parallelism, ray_remote_args, **read_args)\u001b[0m\n\u001b[1;32m    300\u001b[0m         )\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         requested_parallelism, min_safe_parallelism, read_tasks = ray.get(\n\u001b[0m\u001b[1;32m    303\u001b[0m             get_read_tasks.remote(\n\u001b[1;32m    304\u001b[0m                 \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2307\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2309\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2310\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(FileNotFoundError)\u001b[0m: \u001b[36mray::_get_read_tasks()\u001b[39m (pid=424007, ip=10.3.27.163)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/read_api.py\", line 1586, in _get_read_tasks\n    reader = ds.create_reader(**kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/parquet_datasource.py\", line 165, in create_reader\n    return _ParquetDatasourceReader(**kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/parquet_datasource.py\", line 203, in __init__\n    _handle_read_os_error(e, paths)\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/file_meta_provider.py\", line 367, in _handle_read_os_error\n    raise error\n  File \"/usr/local/lib/python3.8/dist-packages/ray/data/datasource/parquet_datasource.py\", line 199, in __init__\n    pq_ds = pq.ParquetDataset(\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/parquet/core.py\", line 1724, in __new__\n    return _ParquetDatasetV2(\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/parquet/core.py\", line 2423, in __init__\n    self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py\", line 755, in dataset\n    return _filesystem_dataset(source, **kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py\", line 442, in _filesystem_dataset\n    fs, paths_or_selector = _ensure_multiple_sources(source, filesystem)\n  File \"/usr/local/lib/python3.8/dist-packages/pyarrow/dataset.py\", line 361, in _ensure_multiple_sources\n    raise FileNotFoundError(info.path)\nFileNotFoundError: ../PySpark/taxi_data.parquet/part-00005-8a3a5378-d47c-4325-84e6-e9d4ff2c5b4d-c000.snappy.parquet"
     ]
    }
   ],
   "source": [
    "direct = '../PySpark/taxi_data.parquet/'\n",
    "list_files = os.listdir(direct)\n",
    "filter_files = []\n",
    "\n",
    "for file in list_files:\n",
    "    if file[-8:] == '.parquet':\n",
    "        filter_files.append(direct + file)\n",
    "        \n",
    "# Read Parquet files in parallel\n",
    "ds = ray.data.read_parquet(filter_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63313fa1-5bfc-4f14-8e8d-06b764a34512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vendor_id: string\n",
       "pickup_datetime: timestamp[ns]\n",
       "dropoff_datetime: timestamp[ns]\n",
       "passenger_count: int32\n",
       "trip_distance: double\n",
       "pickup_longitude: double\n",
       "pickup_latitude: double\n",
       "rate_code: int32\n",
       "store_and_fwd_flag: string\n",
       "dropoff_longitude: double\n",
       "dropoff_latitude: double\n",
       "payment_type: string\n",
       "fare_amount: double\n",
       "surcharge: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "total_amount: double\n",
       "-- schema metadata --\n",
       "org.apache.spark.version: '3.3.1'\n",
       "org.apache.spark.sql.parquet.row.metadata: '{\"type\":\"struct\",\"fields\":[{\"' + 1283"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fcb1b74-66bf-487a-9617-551cab2b176f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 15,811,595\n"
     ]
    }
   ],
   "source": [
    "total_rows = ds.count()\n",
    "print('Total rows: {:,}'.format(total_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7b5156-1f0c-41f7-b2e5-bad4c83f1254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 820.32it/s]\n",
      "Read progress: 100%|██████████| 1/1 [00:00<00:00, 895.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-29 18:07:30</td>\n",
       "      <td>2012-03-29 18:33:42</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-73.972451</td>\n",
       "      <td>40.754851</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.985300</td>\n",
       "      <td>40.768561</td>\n",
       "      <td>CSH</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-30 15:30:10</td>\n",
       "      <td>2012-03-30 15:36:13</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-73.954359</td>\n",
       "      <td>40.766108</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.971284</td>\n",
       "      <td>40.744712</td>\n",
       "      <td>CSH</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-30 08:11:45</td>\n",
       "      <td>2012-03-30 08:17:33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-73.953557</td>\n",
       "      <td>40.771037</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.961918</td>\n",
       "      <td>40.777928</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-31 11:55:39</td>\n",
       "      <td>2012-03-31 12:00:41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-73.985258</td>\n",
       "      <td>40.761061</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.979457</td>\n",
       "      <td>40.762585</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2012-03-12 20:18:00</td>\n",
       "      <td>2012-03-12 20:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-73.957805</td>\n",
       "      <td>40.765215</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.950527</td>\n",
       "      <td>40.775135</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0       CMT 2012-03-29 18:07:30 2012-03-29 18:33:42                1   \n",
       "1       CMT 2012-03-30 15:30:10 2012-03-30 15:36:13                1   \n",
       "2       CMT 2012-03-30 08:11:45 2012-03-30 08:17:33                1   \n",
       "3       CMT 2012-03-31 11:55:39 2012-03-31 12:00:41                1   \n",
       "4       VTS 2012-03-12 20:18:00 2012-03-12 20:20:00                1   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  rate_code  \\\n",
       "0           2.60        -73.972451        40.754851          1   \n",
       "1           2.00        -73.954359        40.766108          1   \n",
       "2           0.80        -73.953557        40.771037          1   \n",
       "3           0.60        -73.985258        40.761061          1   \n",
       "4           1.01        -73.957805        40.765215          1   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude payment_type  \\\n",
       "0                  N         -73.985300         40.768561          CSH   \n",
       "1                  N         -73.971284         40.744712          CSH   \n",
       "2                  N         -73.961918         40.777928          CSH   \n",
       "3                  N         -73.979457         40.762585          CSH   \n",
       "4               None         -73.950527         40.775135          CSH   \n",
       "\n",
       "   fare_amount  surcharge  mta_tax  tip_amount  tolls_amount  total_amount  \n",
       "0         13.7        1.0      0.5         0.0           0.0          15.2  \n",
       "1          6.9        0.0      0.5         0.0           0.0           7.4  \n",
       "2          4.9        0.0      0.5         0.0           0.0           5.4  \n",
       "3          4.5        0.0      0.5         0.0           0.0           5.0  \n",
       "4          4.5        0.5      0.5         0.0           0.0           5.5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataframe\n",
    "ds.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddb70ef0-7647-4e21-a500-ba5a327f16dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArrowRow({'vendor_id': 'CMT',\n",
       "           'pickup_datetime': Timestamp('2012-03-29 18:07:30'),\n",
       "           'dropoff_datetime': Timestamp('2012-03-29 18:33:42'),\n",
       "           'passenger_count': 1,\n",
       "           'trip_distance': 2.6,\n",
       "           'pickup_longitude': -73.972451,\n",
       "           'pickup_latitude': 40.754851,\n",
       "           'rate_code': 1,\n",
       "           'store_and_fwd_flag': 'N',\n",
       "           'dropoff_longitude': -73.9853,\n",
       "           'dropoff_latitude': 40.768561,\n",
       "           'payment_type': 'CSH',\n",
       "           'fare_amount': 13.7,\n",
       "           'surcharge': 1.0,\n",
       "           'mta_tax': 0.5,\n",
       "           'tip_amount': 0.0,\n",
       "           'tolls_amount': 0.0,\n",
       "           'total_amount': 15.2})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1f0d578-d176-4bcc-b522-3058592951e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 1.99 GB\n"
     ]
    }
   ],
   "source": [
    "def convert_size(size_bytes):\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "total_bytes = ds.size_bytes()\n",
    "print(\"Total size: {}\".format(convert_size(total_bytes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3b4adca-b3a7-4749-906f-488e68a85f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in-memory size: 1.99 GB\n"
     ]
    }
   ],
   "source": [
    "# In order to get the in-memory size, we can trigger full \n",
    "# reading of the dataset and inspect the size in bytes\n",
    "\n",
    "total_bytes = ds.fully_executed().size_bytes()\n",
    "print(\"Total in-memory size: {}\".format(convert_size(total_bytes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b1e6137-d900-48b4-9282-66c779ea6e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffle Map: 100%|██████████| 23/23 [00:00<00:00, 525.32it/s]\n",
      "Shuffle Reduce: 100%|██████████| 1/1 [00:00<00:00, 79.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ArrowRow({'max(trip_distance)': 100.0,\n",
       "          'max(tip_amount)': 200.0,\n",
       "          'max(passenger_count)': 208})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the longets trip distance, largest tip amount, and most number of passengers?\n",
    "ds.max([\"trip_distance\", \"tip_amount\", \"passenger_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33a60146-0998-44dd-9d08-ba4c74e87f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map_Batches: 100%|██████████| 23/23 [00:01<00:00, 15.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Drop some columns.\n",
    "ds = ds.drop_columns([\"store_and_fwd_flag\", \"mta_tax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "720c9ec2-9567-4308-b282-1360a4f36e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-29 18:07:30</td>\n",
       "      <td>2012-03-29 18:33:42</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-73.972451</td>\n",
       "      <td>40.754851</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.985300</td>\n",
       "      <td>40.768561</td>\n",
       "      <td>CSH</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-30 15:30:10</td>\n",
       "      <td>2012-03-30 15:36:13</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-73.954359</td>\n",
       "      <td>40.766108</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.971284</td>\n",
       "      <td>40.744712</td>\n",
       "      <td>CSH</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-30 08:11:45</td>\n",
       "      <td>2012-03-30 08:17:33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-73.953557</td>\n",
       "      <td>40.771037</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.961918</td>\n",
       "      <td>40.777928</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2012-03-31 11:55:39</td>\n",
       "      <td>2012-03-31 12:00:41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-73.985258</td>\n",
       "      <td>40.761061</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979457</td>\n",
       "      <td>40.762585</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2012-03-12 20:18:00</td>\n",
       "      <td>2012-03-12 20:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-73.957805</td>\n",
       "      <td>40.765215</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.950527</td>\n",
       "      <td>40.775135</td>\n",
       "      <td>CSH</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_id     pickup_datetime    dropoff_datetime  passenger_count  \\\n",
       "0       CMT 2012-03-29 18:07:30 2012-03-29 18:33:42                1   \n",
       "1       CMT 2012-03-30 15:30:10 2012-03-30 15:36:13                1   \n",
       "2       CMT 2012-03-30 08:11:45 2012-03-30 08:17:33                1   \n",
       "3       CMT 2012-03-31 11:55:39 2012-03-31 12:00:41                1   \n",
       "4       VTS 2012-03-12 20:18:00 2012-03-12 20:20:00                1   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  rate_code  \\\n",
       "0           2.60        -73.972451        40.754851          1   \n",
       "1           2.00        -73.954359        40.766108          1   \n",
       "2           0.80        -73.953557        40.771037          1   \n",
       "3           0.60        -73.985258        40.761061          1   \n",
       "4           1.01        -73.957805        40.765215          1   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude payment_type  fare_amount  surcharge  \\\n",
       "0         -73.985300         40.768561          CSH         13.7        1.0   \n",
       "1         -73.971284         40.744712          CSH          6.9        0.0   \n",
       "2         -73.961918         40.777928          CSH          4.9        0.0   \n",
       "3         -73.979457         40.762585          CSH          4.5        0.0   \n",
       "4         -73.950527         40.775135          CSH          4.5        0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  total_amount  \n",
       "0         0.0           0.0          15.2  \n",
       "1         0.0           0.0           7.4  \n",
       "2         0.0           0.0           5.4  \n",
       "3         0.0           0.0           5.0  \n",
       "4         0.0           0.0           5.5  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2788b3e0-f73c-4aa2-9932-0fc63f55cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sort Sample: 100%|██████████| 23/23 [00:00<00:00, 124.23it/s]\n",
      "Shuffle Map: 100%|██████████| 23/23 [01:03<00:00,  2.77s/it]\n",
      "Shuffle Reduce: 100%|██████████| 23/23 [00:00<00:00, 694.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 350 ms, sys: 154 ms, total: 504 ms\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PandasRow({'passenger_count': 0, 'count()': 335328}),\n",
       " PandasRow({'passenger_count': 1, 'count()': 11051985}),\n",
       " PandasRow({'passenger_count': 2, 'count()': 2242606}),\n",
       " PandasRow({'passenger_count': 3, 'count()': 666836}),\n",
       " PandasRow({'passenger_count': 4, 'count()': 312434}),\n",
       " PandasRow({'passenger_count': 5, 'count()': 1148624}),\n",
       " PandasRow({'passenger_count': 6, 'count()': 389102}),\n",
       " PandasRow({'passenger_count': 208, 'count()': 8})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ds.groupby(\"passenger_count\").count().take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5e05ab8-2978-40a6-a79f-7360ef8d2503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map_Batches: 100%|██████████| 23/23 [00:02<00:00, 11.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter our records with negative passenger counts.\n",
    "ds = ds.map_batches(lambda df: df[df[\"passenger_count\"] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98602128-1395-4d11-b154-34598ca260ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sort Sample: 100%|██████████| 23/23 [00:00<00:00, 143.49it/s]\n",
      "Shuffle Map: 100%|██████████| 23/23 [01:03<00:00,  2.76s/it]\n",
      "Shuffle Reduce: 100%|██████████| 23/23 [00:00<00:00, 709.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PandasRow({'passenger_count': 1, 'mean(trip_distance)': 2.8091539203138622}),\n",
       " PandasRow({'passenger_count': 2, 'mean(trip_distance)': 3.022558545727604}),\n",
       " PandasRow({'passenger_count': 3, 'mean(trip_distance)': 2.9073175263483075}),\n",
       " PandasRow({'passenger_count': 4, 'mean(trip_distance)': 2.9382245850323594}),\n",
       " PandasRow({'passenger_count': 5, 'mean(trip_distance)': 2.9500852933597073}),\n",
       " PandasRow({'passenger_count': 6, 'mean(trip_distance)': 2.9708847294539726}),\n",
       " PandasRow({'passenger_count': 208, 'mean(trip_distance)': 0.0})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean trip distance grouped by passenger count.\n",
    "ds.groupby(\"passenger_count\").mean(\"trip_distance\").take()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc127ab7-0276-4149-982d-fa22ecc17c48",
   "metadata": {},
   "source": [
    "## Advanced Aside - Projection and Filter Pushdown\n",
    "\n",
    "Note that Ray Datasets' Parquet reader supports projection (column selection) and row filter pushdown, where we can push the above column selection and the row-based filter to the Parquet read. If we specify column selection at Parquet read time, the unselected columns won't even be read from disk!\n",
    "\n",
    "The row-based filter is specified via\n",
    "[Arrow's dataset field expressions](https://arrow.apache.org/docs/6.0/python/generated/pyarrow.dataset.Expression.html#pyarrow.dataset.Expression). See the {ref}`feature guide for reading Parquet data <dataset_supported_file_formats>` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a76d4cdd-2560-4dde-87dd-97acb76682b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parquet Files Sample: 100%|██████████| 2/2 [00:00<00:00, 96.86it/s]\n",
      "2022-12-14 12:45:28,872\tWARNING read_api.py:326 -- ⚠️  The number of blocks in this dataset (23) limits its parallelism to 23 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Read progress: 100%|██████████| 23/23 [00:00<00:00, 721.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Only read the passenger_count and trip_distance columns.\n",
    "import pyarrow as pa\n",
    "filter_expr = (\n",
    "    (pa.dataset.field(\"passenger_count\") <= 10)\n",
    "    & (pa.dataset.field(\"passenger_count\") > 0)\n",
    ")\n",
    "\n",
    "pushdown_ds = ray.data.read_parquet(filter_files,\n",
    "    columns=[\"passenger_count\", \"trip_distance\"],\n",
    "    filter=filter_expr,\n",
    ")\n",
    "\n",
    "# Force full execution of both of the file reads.\n",
    "pushdown_ds = pushdown_ds.fully_executed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb365110-3865-4f4f-8e38-347fd111a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 15,811,587\n"
     ]
    }
   ],
   "source": [
    "total_rows = pushdown_ds.count()\n",
    "print('Total rows: {:,}'.format(total_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eeaee3-5f43-459c-bb5b-0e93a6523913",
   "metadata": {},
   "source": [
    "pushdown_ds.limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b92435ac-2492-48d4-b9c3-a00d19c1ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the pushdown dataset. Deleting the Dataset object\n",
    "# will release the underlying memory in the cluster.\n",
    "del pushdown_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825c40f-bf71-43ee-ac35-091abb564840",
   "metadata": {},
   "source": [
    "## Ingesting into Model Trainers\n",
    "\n",
    "Now that we've learned more about our data and we have cleaned up our dataset a bit, we now look at how we can feed this dataset into some dummy model trainers.\n",
    "\n",
    "First, let's do a full global random shuffle of the dataset to decorrelate these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63c2b234-914c-4495-a4e5-85c9204a168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffle Map: 100%|██████████| 23/23 [00:00<00:00, 31.55it/s]\n",
      "Shuffle Reduce: 100%|██████████| 23/23 [00:01<00:00, 18.48it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.random_shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d24d61-e37a-44c5-9b36-5c5a57853c42",
   "metadata": {},
   "source": [
    "* We define a dummy ``Trainer`` actor, where each trainer will consume a dataset shard in batches and simulate model training.\n",
    "\n",
    "*In a real training workflow, we would feed ``ds`` to {ref}`Ray Train <train-docs>`, which would do this sharding and creation of training actors for us, under the hood.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d23d0cf2-0adf-4b48-a926-cb2d2059a9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Actor(Trainer, 8716ad277846ff83b245e4a601000000),\n",
       " Actor(Trainer, c769ef29f2540a35e181a47601000000),\n",
       " Actor(Trainer, 1b6d4f8c0d584d419d969f6101000000),\n",
       " Actor(Trainer, 63d051ee100ba2f70fa40c8101000000)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ray.remote\n",
    "class Trainer:\n",
    "    def __init__(self, rank: int):\n",
    "        pass\n",
    "\n",
    "    def train(self, shard: ray.data.Dataset) -> int:\n",
    "        for batch in shard.iter_batches(batch_size=256):\n",
    "            pass\n",
    "        return shard.count()\n",
    "\n",
    "trainers = [Trainer.remote(i) for i in range(4)]\n",
    "trainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4598b5-d274-4ed3-927a-033b8688067e",
   "metadata": {},
   "source": [
    "* Next, we split the dataset into ``len(trainers)`` shards, ensuring that the shards are of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a17a7df7-9cf0-482b-a1c9-7b0c1bac1be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset(num_blocks=6, num_rows=3952898, schema={vendor_id: object, pickup_datetime: datetime64[ns], dropoff_datetime: datetime64[ns], passenger_count: int32, trip_distance: float64, pickup_longitude: float64, pickup_latitude: float64, rate_code: int32, dropoff_longitude: float64, dropoff_latitude: float64, payment_type: object, fare_amount: float64, surcharge: float64, tip_amount: float64, tolls_amount: float64, total_amount: float64}),\n",
       " Dataset(num_blocks=7, num_rows=3952898, schema={vendor_id: object, pickup_datetime: datetime64[ns], dropoff_datetime: datetime64[ns], passenger_count: int32, trip_distance: float64, pickup_longitude: float64, pickup_latitude: float64, rate_code: int32, dropoff_longitude: float64, dropoff_latitude: float64, payment_type: object, fare_amount: float64, surcharge: float64, tip_amount: float64, tolls_amount: float64, total_amount: float64}),\n",
       " Dataset(num_blocks=7, num_rows=3952898, schema={vendor_id: object, pickup_datetime: datetime64[ns], dropoff_datetime: datetime64[ns], passenger_count: int32, trip_distance: float64, pickup_longitude: float64, pickup_latitude: float64, rate_code: int32, dropoff_longitude: float64, dropoff_latitude: float64, payment_type: object, fare_amount: float64, surcharge: float64, tip_amount: float64, tolls_amount: float64, total_amount: float64}),\n",
       " Dataset(num_blocks=6, num_rows=3952898, schema={vendor_id: object, pickup_datetime: datetime64[ns], dropoff_datetime: datetime64[ns], passenger_count: int32, trip_distance: float64, pickup_longitude: float64, pickup_latitude: float64, rate_code: int32, dropoff_longitude: float64, dropoff_latitude: float64, payment_type: object, fare_amount: float64, surcharge: float64, tip_amount: float64, tolls_amount: float64, total_amount: float64})]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shards = ds.split(n=len(trainers), equal=True)\n",
    "shards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8cbb6-9725-4e95-ad75-234d140c2e3d",
   "metadata": {},
   "source": [
    "* Finally, we simulate training, passing each shard to the corresponding trainer. The number of rows per shard is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdb0301d-a280-42d7-be8e-0f3efc0dd30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3952898, 3952898, 3952898, 3952898]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get([w.train.remote(s) for w, s in zip(trainers, shards)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc21745-4fb4-4186-9a72-a59d93f1cccb",
   "metadata": {},
   "source": [
    "## Parallel Batch Inference\n",
    "\n",
    "Refer to the blog on [Model Batch Inference in Ray](https://www.anyscale.com/blog/model-batch-inference-in-ray-actors-actorpool-and-datasets) for an overview of batch inference strategies in Ray and additional examples.\n",
    "\n",
    "After we've trained a model, we may want to perform batch (offline) inference on such a tabular dataset. With Ray Datasets, this is as easy as a {meth}`ds.map_batches() <ray.data.Dataset.map_batches>` call!\n",
    "\n",
    "First, we define a callable class that will cache the loading of the model in its constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c331b1e-249b-48aa-b9be-d44110d5bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_model():\n",
    "    # A dummy model.\n",
    "    def model(batch: pd.DataFrame) -> pd.DataFrame:\n",
    "        return pd.DataFrame({\"score\": batch[\"passenger_count\"] % 2 == 0})\n",
    "    \n",
    "    return model\n",
    "\n",
    "class BatchInferModel:\n",
    "    def __init__(self):\n",
    "        self.model = load_model()\n",
    "    def __call__(self, batch: pd.DataFrame) -> pd.DataFrame:\n",
    "        return self.model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7fee5080-cc70-48b6-9c20-2cc2b2168fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress (19 actors 5 pending): 100%|██████████| 23/23 [00:08<00:00,  2.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.map_batches(BatchInferModel, batch_size=2048, compute=\"actors\").take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22e7dbae-e035-4d08-b0f8-3ac193abdf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress (214 actors 54 pending):  57%|█████▋    | 13/23 [00:24<00:12,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +35m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress (214 actors 54 pending):  87%|████████▋ | 20/23 [00:29<00:02,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +35m20s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress (214 actors 54 pending): 100%|██████████| 23/23 [00:29<00:00,  1.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False})]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +35m55s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +36m30s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +37m5s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +37m40s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +38m15s)\u001b[0m Error: No available node types can fulfill resource request {'CPU': 1.0, 'GPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n"
     ]
    }
   ],
   "source": [
    "ds.map_batches(\n",
    "    BatchInferModel,\n",
    "    batch_size=256,\n",
    "    #num_gpus=1,  # Uncomment this to run this on GPUs!\n",
    "    compute=\"actors\",\n",
    ").take()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa9d081-d280-40d0-bfb2-93ed0da2272f",
   "metadata": {},
   "source": [
    "* We can also configure the autoscaling actor pool that this inference stage uses, setting upper and lower bounds on the actor pool size, and even tweak the batch prefetching vs. inference task queueing tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc051f28-0357-45f1-a535-d9a452689cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress (8 actors 0 pending): 100%|██████████| 23/23 [00:33<00:00,  1.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': True}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False}),\n",
       " PandasRow({'score': False})]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.data import ActorPoolStrategy\n",
    "\n",
    "# The actor pool will have at least 2 workers and at most 8 workers.\n",
    "strategy = ActorPoolStrategy(min_size=2, max_size=8)\n",
    "\n",
    "ds.map_batches(\n",
    "    BatchInferModel,\n",
    "    batch_size=256,\n",
    "    #num_gpus=1,  # Uncomment this to run this on GPUs!\n",
    "    compute=strategy,\n",
    ").take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59784b-8212-4fda-96e6-a52ee25b2543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

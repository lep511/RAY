{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f281cc15-627f-4b48-ab6b-ba8eec40c6eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Funciones de Tareas Ray\n",
    "\n",
    "Una virtud de la API de Ray es cómo se basa en conceptos familiares que ya conoces de Python, lo que mantiene los nuevos conceptos tan intuitivos como sea posible. Si quieres encapsular algún trabajo en Python, escribe una función como ésta, que podría ser utilizada para consultar una base de datos para recuperar datos de referencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa598c3e-5919-4685-99df-321bbc5c592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Suppress noisy requests warnings.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057047f1-456b-4aee-8a71-64ee1b3a6d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 14:15:33,472\tWARNING services.py:1732 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67100672 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=2.04gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-01-08 14:15:34,938\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.4</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.10.4', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '172.16.5.4', 'raylet_ip_address': '172.16.5.4', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-01-08_14-15-30_023879_6173/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-01-08_14-15-30_023879_6173/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2023-01-08_14-15-30_023879_6173', 'metrics_export_port': 61010, 'gcs_address': '172.16.5.4:48281', 'address': '172.16.5.4:48281', 'dashboard_agent_listen_port': 52365, 'node_id': '34869929de659b637b392a4a58707a41f246d53f1d417677e403d3d9'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46c9bdb-cc89-4e16-b96d-973264ac02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data = [\n",
    "  \"Fast\", \"and\", \"Simple\", \"Distributed\", \"Computing\"]\n",
    "\n",
    "def get_ref_datum(id):\n",
    "  time.sleep(id/10.0)   # Simulate an \"expensive\" operation\n",
    "  foreign_key = 2*id\n",
    "  value = reference_data[id%len(reference_data)]\n",
    "  return (id, foreign_key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9f2a5a-0159-4ecf-ad77-1317a8569815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4.505 secs, data = [(0, 0, 'Fast'), (1, 2, 'and'), (2, 4, 'Simple'), (3, 6, 'Distributed'), (4, 8, 'Computing'), (5, 10, 'Fast'), (6, 12, 'and'), (7, 14, 'Simple'), (8, 16, 'Distributed'), (9, 18, 'Computing')]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data = [get_ref_datum(id) for id in range(10)]\n",
    "duration = time.time() - start\n",
    "print(f'{duration:6.3f} secs, data = {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0446a12a-74e2-48be-a0a5-cfc16a2bccda",
   "metadata": {},
   "source": [
    "* ¿Por qué demora 4,5 segundos? Utilizamos *slpeep* durante id/10,0 segundos. Pasamos los valores de id 0 a 9 (10 excluyente), que suman 45. Hay un poco más de tiempo tomado por otros gastos generales. Tenga en cuenta que todas las invocaciones de *get_ref_datum* son independientes entre sí, así que ¿por qué no hacerlas en paralelo? Aquí es donde entra Ray.\n",
    "\n",
    "* Queremos convertir nuestra función síncrona, que se ejecuta en el mismo hilo que el intérprete, en una tarea que pueda ejecutarse en cualquier núcleo de CPU de nuestra máquina o en un cluster multinodo de Ray. He aquí una forma de hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5e6d67-edf1-4de8-bdb5-6e131fa5b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def get_ref_datum_task_first_attempt(id):\n",
    "  return get_ref_datum(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d1447-3387-4ba1-b8cc-3177f2ce9c88",
   "metadata": {},
   "source": [
    "* El decorador *@ray.remote* marca las definiciones de tareas. Simplemente llamamos a *get_ref_datum()*. Sin embargo, esta tarea podría ejecutarse en cualquier parte de un clúster Ray, y una implementación más realista podría utilizar un gran conjunto de datos de referencia, así que vamos a utilizar nuestro almacén de objetos distribuido para mantener los reference_data y luego recuperarlos cuando sea necesario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4e5830-0aa2-4b73-8156-2e63d355499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data_object_ref = ray.put(reference_data)\n",
    "\n",
    "@ray.remote\n",
    "def get_ref_datum_task(id):\n",
    "  time.sleep(id/10.0)   # Simulate an \"expensive\" operation\n",
    "  foreign_key = 2*id\n",
    "  ref_data = ray.get(ref_data_object_ref)\n",
    "  value = ref_data[id%len(ref_data)]\n",
    "  return (id, foreign_key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd6525-70ac-475d-9086-902c68dc9c79",
   "metadata": {},
   "source": [
    "* Los datos de referencia se colocan en el almacén de objetos distribuidos ray.put(), que devuelve una referencia de objeto de tipo ObjectRef. Los datos de referencia se recuperan del almacén de objetos con ray.get(). Hay una sobrecarga adicional al añadir esta interacción con el almacén de objetos, pero las optimizaciones internas, como la memoria compartida de copia cero, pueden eliminar gran parte de ella. Esto es especialmente importante cuando se invoca get_ref_datum_task() muchas veces concurrentemente, de modo que las instancias reales de la tarea se programan alrededor del cluster. En este caso, tendremos una sola copia de los datos de referencia en cada nodo que los necesite, en lugar de una copia por instancia de tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654eb4fa-7909-4219-b570-7627f771b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.609 secs, data = [(0, 0, 'Fast'), (1, 2, 'and'), (2, 4, 'Simple'), (3, 6, 'Distributed'), (4, 8, 'Computing'), (5, 10, 'Fast'), (6, 12, 'and'), (7, 14, 'Simple'), (8, 16, 'Distributed'), (9, 18, 'Computing')]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_refs = [get_ref_datum_task.remote(id) for id in range(10)]\n",
    "data = ray.get(data_refs)\n",
    "duration = time.time() - start\n",
    "print(f'{duration:6.3f} secs, data = {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1c3a0-c1c8-4bed-91b0-a613ab07da4f",
   "metadata": {},
   "source": [
    "* Las tareas se invocan mediante un método .remote(...) añadido. En Python, sería posible que Ray modificara la función para que puedas llamar a `get_ref_datum_task(id)` directamente, pero ver el .remote(id) en el código hace obvio que Ray está en uso aquí.\n",
    "\n",
    "* Las tareas se ejecutan de forma asíncrona, así que ¿qué se devuelve? Es un `ObjectRef` correspondiente a un futuro. Usamos `ray.get()` para recuperar la lista de objetos de los ids, que se bloquea hasta que se completan todas las tareas.\n",
    "\n",
    "* La parte de los datos es la misma que antes, lo que indica que hemos conservado el orden de los datos resultantes, lo que podría ser importante para tu aplicación, ¡aunque hayamos ejecutado las tareas de forma asíncrona! Sin embargo, el tiempo de ejecución es ahora de sólo un segundo. ¿Por qué un segundo? Todas las tareas ahora se ejecutan en paralelo, por lo que estamos limitados por la tarea más larga, que duerme 9/10,0 segundos. Bien, ¿por qué el tiempo total no es de aproximadamente 0,9 segundos? En mi máquina de prueba, hay ocho trabajadores en ejecución. Puede ver el recuento real en su máquina en el Ray Dashboard discutido anteriormente. El valor por defecto para este número se basa en los núcleos de CPU que tiene disponibles.\n",
    "\n",
    "* Esto significa que las ocho primeras tareas se programan inmediatamente, mientras que las dos últimas tienen que esperar a que haya trabajadores disponibles. Una tarea en espera, para id = 8, se programa muy rápidamente, porque la tarea con id = 0 termina inmediatamente. La segunda y última tarea en espera, para id = 9, espera 0,1 segundos y luego se ejecuta. Por lo tanto, su tiempo total de \"reloj de pared\" es 0,1 + 0,9 = 1,0 segundo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58905ecc-b0db-49d2-8afb-8b453dfdbd57",
   "metadata": {},
   "source": [
    "El código que acabamos de ejecutar tiene dos inconvenientes. En primer lugar, dado que ray.get() es una llamada de bloqueo, nuestro programa principal (el \"controlador\" en la jerga de Ray) se queda ahí sin hacer nada mientras esperamos a que se completen las tareas. Algunas de esas tareas terminan más rápido que otras. Estaría bien procesar esos resultados mientras las tareas más lentas siguen en marcha.\n",
    "\n",
    "En segundo lugar, en el código de producción, las llamadas que se bloquean sin establecer tiempos de espera son arriesgadas. ¿Qué pasa si una tarea remota tarda un tiempo anormalmente largo en completarse, debido a algún problema del sistema? Realmente necesitamos una forma de especificar un tiempo de espera.\n",
    "\n",
    "Resolvamos ambos problemas con nuestro último ejemplo, que utiliza `ray.wait()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3856471-b0cb-433d-9827-fc57b40e5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.003 secs, finished data = [(0, 0, 'Fast')]\n",
      "   0.104 secs, finished data = [(1, 2, 'and')]\n",
      "   0.205 secs, finished data = [(2, 4, 'Simple')]\n",
      "   0.305 secs, finished data = [(3, 6, 'Distributed')]\n",
      "   0.405 secs, finished data = [(4, 8, 'Computing')]\n",
      "   0.506 secs, finished data = [(5, 10, 'Fast')]\n",
      "   0.607 secs, finished data = [(6, 12, 'and')]\n",
      "   0.708 secs, finished data = [(7, 14, 'Simple')]\n",
      "   0.808 secs, finished data = [(8, 16, 'Distributed')]\n",
      "   0.910 secs, finished data = [(9, 18, 'Computing')]\n",
      " 0.910 secs, data = [(0, 0, 'Fast'), (1, 2, 'and'), (2, 4, 'Simple'), (3, 6, 'Distributed'), (4, 8, 'Computing'), (5, 10, 'Fast'), (6, 12, 'and'), (7, 14, 'Simple'), (8, 16, 'Distributed'), (9, 18, 'Computing')]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_refs = [get_ref_datum_task.remote(id) for id in range(10)]\n",
    "data = []\n",
    "while len(data_refs) > 0:\n",
    "  finished, data_refs = ray.wait(data_refs, timeout=5.0)\n",
    "  d = ray.get(finished)\n",
    "  duration = time.time() - start\n",
    "  print(f'  {duration:6.3f} secs, finished data = {d}')\n",
    "  data.extend(d)\n",
    "duration = time.time() - start\n",
    "print(f'{duration:6.3f} secs, data = {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4078529-ccda-4f59-9f7c-47bc26c5f61d",
   "metadata": {},
   "source": [
    "* Fíjate en que el resultado de una tarea se procesa tan pronto como está lista, ¡a partir de sólo 0,002 segundos!\n",
    "\n",
    "* El código está un poco recargado, porque también hemos añadido más sentencias print para que puedas ver lo que está pasando. El modismo central que combina ray.wait() y ray.get() es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "becf7fa6-943e-4c43-8bda-8543b4a85485",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_refs = [get_ref_datum_task.remote(id) for id in range(10)]\n",
    "data = []\n",
    "while len(data_refs) > 0:\n",
    "  finished, data_refs = ray.wait(data_refs, timeout=5.0)\n",
    "  d = ray.get(finished)\n",
    "  data.extend(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85fd782-d925-4f92-a53f-e793323b9e8d",
   "metadata": {},
   "source": [
    "Seguimos haciendo todas las llamadas a .remote() a la vez, porque devuelven inmediatamente los valores ObjectRef de los futuros. Luego hacemos un bucle sobre el subconjunto de futuros que todavía se están ejecutando. ray.wait() vuelve tan pronto como una tarea termina. (Hay un argumento clave-valor opcional para especificar más de una.) Devuelve dos listas, una con las referencias a objetos terminados de las tareas terminadas y la otra con el resto de referencias de las tareas aún en ejecución. A continuación, utilizamos ray.get() para recuperar los valores de las tareas finalizadas. Ahora ray.get() no se bloqueará, porque esas tareas ya están terminadas.\n",
    "\n",
    "Reseteamos el valor de data_refs para que sean los ids restantes, porque nunca querrás pasar referencias de tareas completadas a ray.wait(). Si lo haces, volverá inmediatamente con la primera de las referencias completadas, ¡creando un bucle infinito!\n",
    "\n",
    "Para evitar posibles bloqueos, donde nuestra aplicación se detiene mientras algunas tareas esperan eternamente por recursos que nunca llegarán, pasamos un valor de tiempo de espera opcional de cinco segundos. Si se alcanza el tiempo de espera antes de que se complete ninguna tarea, ray.wait() devolverá una lista vacía para la primera lista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555fb565-1955-4295-ab92-09be40396bfe",
   "metadata": {},
   "source": [
    "### Dependencia de tareas\n",
    "\n",
    "¿Qué ocurre si algunas tareas dependen de los resultados de otras tareas? En nuestro ejemplo, devolvemos una clave_externa, que utilizaremos ahora para ilustrar la elegancia con la que Ray gestiona las dependencias entre tareas. Después de recuperar un dato con una \"clave externa\" (en el sentido SQL del término), utilizaremos esa clave para realizar otra consulta.\n",
    "\n",
    "Por razones que se aclararán en un momento, definiremos una segunda versión de get_ref_datum_task() que toma como argumento una tupla de tres elementos, las mismas tuplas devueltas por las llamadas a la get_ref_datum_task() original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2854a6f8-cded-4b86-8c77-f347a30e1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def get_ref_datum_task2(tuple):\n",
    "  original_id, foreign_key, value = tuple\n",
    "  return tuple, get_ref_datum(foreign_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a23a01-969d-4599-ad72-5ef77126aaa1",
   "metadata": {},
   "source": [
    "Esta segunda versión devuelve una \"tupla de tuplas\" de dos elementos: el primer elemento es la tupla de entrada, y el segundo elemento es una nueva tupla correspondiente a la clave_extranjera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf75bf42-b018-4a9a-9e69-509fcc38e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 4, 'Simple'), (4, 8, 'Computing'))\n",
      "((4, 8, 'Computing'), (8, 16, 'Distributed'))\n",
      "((6, 12, 'and'), (12, 24, 'Simple'))\n"
     ]
    }
   ],
   "source": [
    "refs1 = [get_ref_datum_task.remote(i) for i in [2, 4, 6]]\n",
    "refs2 = [get_ref_datum_task2.remote(i) for i in refs1]\n",
    "for tuple in ray.get(refs2):\n",
    "  print(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b228389-180d-4f2f-bd34-5d3a4cd9e582",
   "metadata": {},
   "source": [
    "Para cada línea de salida, la primera tupla de tres elementos es de la invocación original a get_ref_datum_task(), y la segunda tupla de tres elementos es de la invocación posterior a get_ref_datum_task2().\n",
    "\n",
    "La razón de la nueva definición de tarea es permitirnos simplemente pasar un ObjectRef a get_ref_datum_task2(). Ray sabe que necesitamos pasar una tupla a esta tarea, por lo que Ray llama automáticamente a ray.get() en el ObjectRef y pasa la tupla devuelta a la tarea. Ray también programa cualquier tarea get_ref_datum_task2() después de que la tarea get_ref_datum_task() correspondiente haya finalizado.\n",
    "\n",
    "Así, Ray hace dos cosas convenientes para las tareas dependientes:\n",
    "\n",
    "* Podemos pasar ObjectRefs a las tareas y Ray se encargará del boilerplate de extraer los resultados.\n",
    "\n",
    "* No necesitamos esperar a que el primer conjunto de tareas se complete antes de iniciar las tareas dependientes. Ray se encarga de todo esto automáticamente.\n",
    "\n",
    "Si este ejemplo aún no está claro, intente reescribirlo para utilizar ray.get() para recuperar primero los resultados de las llamadas a get_ref_datum_task(), bloqueando hasta que terminen. Luego pasa las tuplas resultantes explícitamente a las llamadas get_ref_datum_task2().\n",
    "\n",
    "En otras palabras, haz el trabajo que Ray hace por ti. ¡Verás cuánta repetición no necesitas escribir! Así, incluso cuando se trabaja con tareas que tienen gráficos complejos de dependencias, escribimos código muy similar al código Python síncrono que estamos acostumbrados a escribir, sin embargo, se ejecuta a través de un clúster de forma asíncrona, con Ray gestionando las dependencias por nosotros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c810f-4b2f-4593-8a08-38993c36ee90",
   "metadata": {},
   "source": [
    "### De las clases a los Ray Actors\n",
    "\n",
    "Por muy útil que sea la abstracción de tareas, hay una deficiencia flagrante a la que se enfrentan las aplicaciones reales: ¿cómo gestionamos el estado distribuido?\n",
    "\n",
    "El modelo de actores de Ray amplía el concepto familiar de clases orientadas a objetos para encapsular el estado y la computación.\n",
    "\n",
    "#### ¿QUÉ SON LOS ACTORES?\n",
    "El modelo de actor de concurrencia fue desarrollado en 1973 por Carl Hewitt. Los actores se comunican entre sí mediante el envío de mensajes, que se procesan en el orden en que se reciben de forma segura. De este modo, se eliminan muchos de los retos de la programación multihilo. Están diseñados para contener estados en evolución y soportar actualizaciones y accesos de forma controlada. Otras implementaciones populares de este modelo son Erlang y Akka.\n",
    "\n",
    "Vamos a mejorar nuestra aplicación hasta ahora mediante la definición de un actor que realiza un seguimiento de los recuentos de solicitudes para cada id. Primero, empezaremos con una clase Python simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc4f994-3bf8-4463-b102-9ef75caecd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceDataTracker:\n",
    "  def __init__(self, reference_data_size):\n",
    "    self.size = reference_data_size\n",
    "    self.counts = [0 for _ in range(self.size)]\n",
    "\n",
    "  def increment(self, ref):\n",
    "    refmod = ref%self.size\n",
    "    self.counts[refmod] += 1\n",
    "    return (ref, self.counts[refmod])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3503b7c-47b4-4822-aa89-2a1cce594b36",
   "metadata": {},
   "source": [
    "Al igual que las funciones se amplían a tareas por Ray, las clases se amplían a actores. Podemos subclasificar RefDataTracker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c846315d-9895-4790-87b7-90143c65cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class ReferenceDataTrackerActor(ReferenceDataTracker):\n",
    "  def get_counts(self):\n",
    "    return self.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd6669-7fcd-4e46-b525-3e3a52f2478c",
   "metadata": {},
   "source": [
    "RefDataTrackerActor necesita añadir un método getter para recuperar los recuentos. Ray no soporta la lectura directa de los campos del actor como en una instancia normal de Python.\n",
    "\n",
    "La construcción del actor utiliza .remote():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8e1670e-79ff-41c2-a90f-9848372bb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = ReferenceDataTrackerActor.remote(len(reference_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b371eb2-9e00-433f-b0ef-7376121f40df",
   "metadata": {},
   "source": [
    "Por último, vamos a redefinir `get_ref_datum_task()` para invocar al actor rastreador para incrementar el recuento del id. Pasamos el rastreador como argumento.\n",
    "\n",
    "Ten en cuenta que los métodos de actor se invocan con .remote(), igual que las tareas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e32e37c-a9da-442b-b5bd-307a0f347a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.912 secs:\n",
      "data = [(0, 0, 'Fast'), (1, 2, 'and'), (2, 4, 'Simple'), (3, 6, 'Distributed'), (4, 8, 'Computing'), (5, 10, 'Fast'), (6, 12, 'and'), (7, 14, 'Simple'), (8, 16, 'Distributed'), (9, 18, 'Computing')]\n",
      "counts = [6, 6, 6, 6, 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def get_reference_datum_task(id, tracker):\n",
    "  time.sleep(id/10.0)   # Simulate an \"expensive\" operation\n",
    "  foreign_key = 2*id\n",
    "  idmod = id%len(reference_data)\n",
    "  value = reference_data[idmod]\n",
    "  tracker.increment.remote(idmod) # Ignore returned ref\n",
    "  return (id, foreign_key, value)\n",
    "\n",
    "start = time.time()\n",
    "tuple_refs = [\n",
    "  get_reference_datum_task.remote(i, tracker)\n",
    "    for i in range(10)]\n",
    "data = ray.get(tuple_refs)\n",
    "counts = ray.get(tracker.get_counts.remote())\n",
    "duration = time.time() - start\n",
    "print(f\"\"\"{duration:6.3f} secs:\n",
    "data = {data}\n",
    "counts = {counts}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40655c01-5ac4-46e3-b069-2ed46c677025",
   "metadata": {},
   "source": [
    "* Los datos son los mismos que antes. El recuento indica que cada valor se ha solicitado dos veces.\n",
    "\n",
    "* Si ejecutas de nuevo el código anterior, los recuentos serán cuatro, porque el actor rastreador sigue ejecutándose.\n",
    "\n",
    "Las librerías ray para ML proporcionan ejemplos más sofisticados de actores utilizados para el estado distribuido. Un ejemplo interesante es la implementación de un servidor de parámetros con un conjunto de actores. Un servidor de parámetros es una base de datos especializada para almacenar y servir parámetros de modelos gigantes. A partir de un cierto tamaño, es mejor fragmentar el conjunto de parámetros, un fragmento por actor, para mejorar el rendimiento. El estado distribuido también puede replicarse para una mayor resistencia y recuperación de errores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
